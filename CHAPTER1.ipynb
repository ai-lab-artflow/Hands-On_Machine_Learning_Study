{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <br>\n",
    "<br>\n",
    "\n",
    "# <center>Hands-On Machine Learning with Scikit-Learn & TensolFlow</center>\n",
    "<br>\n",
    "\n",
    "## <center> CHAPTER 1 한눈에 보는 머신 러닝 </center>\n",
    "<br>     \n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "### <div style=\"text-align: right\"> 발표자 : 윤현근 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 머신러닝을 어떻게 정의할 수 있나요?\n",
    "- 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지를 말해보세요. \n",
    "- 레이블된 훈련 세트란 무엇인가요?\n",
    "- 가장 널리 사용되는 지도 학습 작업 두 가지는 무엇인가요? \n",
    "- 보편적인 비지도 학습 작업 네 가지는 무엇인가요? \n",
    "- 사전 정보가 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있나요? \n",
    "- 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하나요? \n",
    "- 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있나요? \n",
    "- 온라인 학습 시스템이 무엇인가요? \n",
    "- 외부 메모리 학습이 무엇인가요? \n",
    "- 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가요? \n",
    "- 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있나요? \n",
    "- 모델 기반 알고리즘이 찾는 것은 무엇인가요? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가요? 예측은 어떻게 만드나요? \n",
    "- 머신러닝의 주요 도전 과제는 무엇인가요?\n",
    "- 모델이 훈련 데이터에서의 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 건가요? 가능한 해결책 세 가지는 무엇인가요? \n",
    "- 테스트 세트가 무엇이고 왜 사용해야 하나요? \n",
    "- 검증 세트의 목적은 무엇인가요? \n",
    "- 테스트 세트를 사용해 하이퍼파라미터를 튜닝하면 어떤 문제가 생기나요? \n",
    "- 교차 검증이 무엇이고, 왜 하나의 검증 세트보다 선호하나요? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 데이터 사이언티스트란?\n",
    "\n",
    "![DataScientist](images/Data_Scientist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 데이터 사이언스란?\n",
    "![DataScience](images/Data_Science.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.1 머신 러닝이란?\n",
    ">[머신러닝은] 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야다 \n",
    "                                                                                   \n",
    "                                                                       -아서 사무엘(Arthur Samuel, 1959)\n",
    "\n",
    "> 어떤 작업 T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 작업 T와 성능 측정 P에 대해 경험 E로 학습한 것이다.\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "                                                                       - 톰 미첼(Tom Mitchell, 1997)\n",
    "\n",
    " 위키백과 문서를 모두 내려받는 것 -> 많은 데이터를 갖게 되는 것 : 머신 러닝 X\n",
    " \n",
    " ### 1.2 왜 머신 러닝을 사용하는가?\n",
    "\n",
    "- 기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 : 하나의 머신러닝 모델이 코드를 간단하고 더 잘 수행되도록 할 수 있습니다.\n",
    "- 전통적인 방식으로는 전혀 해결 방법이 없는 복잡한 문제 : 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾을 수 있습니다.\n",
    "-  유동적인 환경 : 머신러닝 시스템은 새로운 데이터에 적응할 수 있습니다.\n",
    "-  복잡한 문제와 대량의 데이터에서 통찰 얻기 : 겉으로는 보이지 않던 패턴을 머신러닝 기술을 통해 발견(**데이터마이닝**<sup>data mining</sup>)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3 머신러닝 시스템의 종류\n",
    "\n",
    "- 사람의 감독 하에 훈련하는 것인지 그렇지 않은 것인지(지도, 비지도, 준지도, 강화 학습)\n",
    "-  실시간으로 점진적인 학습을 하는지 아닌지(온라인 학습과 배치 학습)\n",
    "-  단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교하는 것인지 아니면 훈련 데이터셋에서 과학자들처럼 패턴을 발견하여 예측 모델을 만드는지(사례 기반 학습과 모델 기반 학습)\n",
    "\n",
    "-> 서로 배타적이지 않으며 연결 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.3.1  지도 학습과 비지도 학습\n",
    " 학습하는 동안의 감독 형태나 정보량'에 따라 분류\n",
    "\n",
    "#### 지도학습(supervised learning)\n",
    "\n",
    "-> 훈련데이터에 레이블 포함\n",
    "\n",
    "- 회귀(regression) : **예측 변수**<sup>predictor variable</sup>라 부르는 **특성**<sup>featrue</sup>(주행거리, 연식, 브랜드 등)을 사용해 중고차 가격 같은 **타깃** 수치를 예측하는 것(*아날로그적*, 확률등)\n",
    "- 분류 (Classification) : 전형적 지도 학습(*디지털*)\n",
    "\n",
    "**이외에 가장 중요한 지도 학습 알고리즘**\n",
    "- k-최근접 이웃 <sup> k-Nearest Neighbors</sup>\n",
    "- 선형 회귀 <sup>Linear Regression</sup>\n",
    "- 로지스틱 회귀 <sup>Logistic Regression</sup>\n",
    "- 서포트 벡터 머신 <sup>Support Vector Machines(SVM)</sup>\n",
    "- 결정 트리 <sup>Decision Tree</sup>와 랜덤 포레스트 <sup>Random Forests</sup>\n",
    "- 신경망 <sup>Neural networks</sup>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 비지도 학습(unsupervised learning)\n",
    "\n",
    "-> 훈련데이터에 레이블 미포함\n",
    "\n",
    "가장 중요한 비지도 학습 알고리즘\n",
    "\n",
    "- 군집 <sup>clustering</sup>\n",
    "\t- k-평균<sup>k-Means</sup>\n",
    "\t- 계층 군집 분석<sup>Hierarchical Cluster Analysis</sup>(HCA)\n",
    "\t- 기댓값 최대화<sup>Expectation Maximization</sup>\n",
    "- 시각화<sup>visualization</sup>와 차원 축소<sup>dimensionality reduction</sup>\n",
    "\t- 주성분 분석<sup>Principal Component Analysis</sup>(PCA)\n",
    "\t- 커널<sup>kernel</sup>PCA\n",
    "\t- 지역적 선형 임베딩<sup>Locally-Linear Embedding</sup>(LLE)\n",
    "\t- t-SNE<sup>t-distributed Stochastic Neighbor Embedding</sup>\n",
    "- 연관 규칙 학습<sup>Assiociation rule learning</sup>\n",
    "\t- 어프라이어리<sup>Apriori</sup>\n",
    "\t-  이클렛<sup>Eclat</sup>\n",
    "\n",
    "시각화<sup>visualization</sup>알고리즘 : 도식화 가능한 2D나 3D 표현 , 가능한 구조 유지<br>\n",
    "차원 축소<sup>dimensionality reduction</sup> : 상관관계가 있는 여러 특성을 하나로 합치는 것  ex) 주행거리, 연식 -> 차의 마모 (**특성 추출**)<br>\n",
    "이상치 탐지<sup>anomaly detection</sup> : 이상 거래 감지, 제조 결함, 학습 알고리즘 주입 전 데이터셋에 이상한 값을 자동으로 제거<br>\n",
    "연관 규칙 학습<sup>association rule learning</sup> : 대량의 데이터에서 특성 간의 흥미로운 관계\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 준지도 학습<sup>semisupervised learning</sup>\n",
    "\n",
    "레이블이 일부만 존재\n",
    "\n",
    "ex) 페이스북 사진 속 인물 분류\n",
    "\n",
    "#### 강화 학습<sup>Reinforcement Learning</sup>\n",
    "\n",
    "학습하는 시스템을 **에이전트**, 환경을 관찰해서 행동을 실행하고 보상 또는 벌점을 받습니다. 가장 큰 보상을 얻기 위해 **정책**<sup>policdy</sup>이라 부르는최상 전략을 스스로 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.3.2 배치 학습과 온라인 학습\n",
    "\n",
    "입력 데이터의 스트림<sup>stream</sup>으로부터 점진적으로 학습할 수 있는지 여부\n",
    "\n",
    "**배치 학습**<sup>batch learning</sup>\n",
    "\n",
    "- 가용한 데이터를 모두 사용해 훈련\n",
    "- 제품 시스템에 적용하면 더 이상의 학습없이 실행\n",
    "- 많은 컴퓨팅 자원 필요(CPU, 메모리 공간, 디스크 공간, 디스크 IO, 네트워크 IO 등)\n",
    "- 자원이 제한된 시스템(예 - 스마트폰, 화성 탐사 로버)이 스스로 학습해야 할 때 많은 자원 사용하면 심각한 문제\n",
    "\n",
    "**온라인 학습**<sup>online learning</sup>\n",
    "\n",
    "- 데이터를 순차적으로 한 개씩 또는 미니배치<sup>mini-batch</sup>라 부르는 작은 묶음 단위로 주입\n",
    "- 빠른 변화에 스스로 적응해야하는 시스템에 적합, 컴퓨팅 자원이 제한된 경우\n",
    "- 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋을 학습하는 시스템(**외부 메모리**<sup>out-of-core</sup> 학습)\n",
    "- 전체 프로세스는 보통 오프라인, 따라서 **점진적 학습**<sup>incremental learning</sup>으로 생각\n",
    "- **학습률**<sup>learning rate</sup> : 변화는 데이터에 얼마나 빠르게 적응할 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.3.3 사례 기반 학습과 모델 기반 학습\n",
    "\n",
    "어떻게 **일반화**되는가에 따라 분류\n",
    "\n",
    "**사례 기반 학습**<sup>instance-based learning</sup>\n",
    "\n",
    "- **유사도**<sup>similarity</sup>를 측정하여 새로운 데이터를 일반화\n",
    "- 예를 들어 스팸 필터를 만드는 경우 가장 간단한 유사도 측정 방법은 공통으로 포함된 단어의 수를 세는 것\n",
    "\n",
    "**모델 기반 학습**<sup>model-based learning</sup>\n",
    "\n",
    "- 모델을 만들어 **예측**에 사용\n",
    "\t- 데이터를 분석\n",
    "\t- 모델 선택\n",
    "\t- 훈련 데이터로 모델 훈련(비용 함수<sup>cost function</sup> 최소화 하는 모델 파라미터 탐색)\n",
    "\t- 새로운 데이터에 모델을 적용해 예측, 잘 일반화되길 기대\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.4 머신러닝의 주요 도전 과제\n",
    "\n",
    "문제점\n",
    " 1. 나쁜 알고리즘\n",
    " 2. 나쁜 데이터\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.4.1 충분하지 않은 양의 훈련 데이터\n",
    "\n",
    "#### 1.4.2 대표성 없는 훈련 데이터\n",
    " - 샘플이 작으면 **샘플링 잡음**<sup>sampling noise</sup>(즉, 우연에 의한 대표성 없는 데이터)\n",
    " - 샘플이 큰 경우도 추출 방법이 잘못된 경우 **샘플링 편향**<sup>sampling bias</sup>\n",
    "\n",
    "#### 1.4.3 낮은 품질의 데이터\n",
    " - 에러, 이상치<sup>outlier</sup>, 잡음\n",
    " - 이상치가 명확하면 무시하거나 수동으로 잘못된 것을 고침\n",
    " - 일부 특성 중 데이터가 누락된 경우 특성을 무시할지, 샘플을 무시할지, 빠진값을 채울지, 특성을 넣은 모델과 제외한 모델을 따로 훈련 시킬것인지 결정\n",
    "#### 1.4.4 관련 없는 특성\n",
    "\n",
    "- **특성 공학**<sup>feature engineering</sup> : 훈련에 사용할 좋은 특성들을 찾는 것\n",
    "    - **특성 선택**<sup>feature selection</sup> : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택\n",
    "    - **특성 추출**<sup>feature extraction</sup> : 특성을 결합하여 더 유용한 특성을 만듬(차원 축소 알고리즘)\n",
    "\t-  새 특성을 만듬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1.4.5 훈련 데이터 과대적합\n",
    "\n",
    "- **과대적합**<sup>overfitting</sup> : 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어짐\n",
    "\t- 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생\n",
    "\t- 파라미터 수가 적은 모델 선택, 훈련데이터에 특성수를 줄임, 모델에 제약을 가하여 단순화(**하이퍼파라미터**<sup>hyperparameter</sup> : 학습하는 동안 적용할 규제의 양, 학습 알고리즘의 파라미터)\n",
    "\t- 훈련 데이터를 더 많이 모음\n",
    "\t- 훈련 데이터의 잡음을 줄임(오류 데이터 수정과 이상치 제거)\n",
    "\n",
    "#### 1.4.6 훈련 데이터 과소적합\n",
    "\n",
    " - **과소적합**<sup>underfitting</sup> : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때\n",
    "\t - 파라미터가 더 많은 강력한 모델 선택\n",
    "\t - 더 좋은 특성 제공(특성 엔지니어링)\n",
    "\t -  모델의 제약을 줄임( 규제 하이퍼파라미터를 감소)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.5 테스트와 검증\n",
    "\n",
    "- **훈련 세트** 와 **테스트 세트** 로 나누어 훈련\n",
    "\t- **일반화 오차**<sup>generalization error</sup>(**외부 샘플 오차**<sup>out-of-sample erro</sup>) : 새로운 샘플에 대한 오류 비율\n",
    "\t- 훈련 오차가 낮지만 일반화 오차가 높다면 과대 적합\n",
    "- **검증 세트**<sup>validation set</sup>\n",
    "\t- **교차 검증**<sup>cross-validation</sup> 기법\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
